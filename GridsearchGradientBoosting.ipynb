{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse.construct import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from random import *    \n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Mutual information\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn import svm\n",
    "\n",
    "df = pd.read_csv(\"kasMasterNew.csv\",sep=';')\n",
    "#print(\"data shape: \", df.shape)\n",
    "#print(\"data head: \", df.head)\n",
    "\n",
    "first_column = df.columns[0]\n",
    "df = df.drop([first_column], axis=1)\n",
    "feature_labels = df.columns\n",
    "last = df.iloc[:,-1]\n",
    "df = df.iloc[:, :-1]\n",
    "\n",
    "X = df\n",
    "y = np.ravel(last.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martin/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:01:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100,...,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.7],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.2, 0.3],\n",
       "                                        'max_depth': [3, 5, 9, 12, 15],\n",
       "                                        'min_child_weight': [1, 3, 7]},\n",
       "                   scoring='accuracy')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import xgboost\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "params={\n",
    " \"learning_rate\"    : [0.05, 0.10, 0.20, 0.30],\n",
    " \"max_depth\"        : [ 3, 5, 9, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 7],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.7]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "scale = StandardScaler()\n",
    "scaler = scale.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "classifier=xgboost.XGBClassifier(min_child_weight= 1, max_depth= 5, learning_rate= 0.2, colsample_bytree = 0.7,  verbosity = 0)\n",
    "#clf = GradientBoostingClassifier()\n",
    "#pipe_gradientboosting=Pipeline[('scl',StandardScaler()),('clf',GradientBoostingClassifier())]\n",
    "\n",
    "random_search=RandomizedSearchCV(estimator = classifier,param_distributions=params,n_iter=50,scoring='accuracy',n_jobs=-1,cv=5)\n",
    "\n",
    "\n",
    "#from datetime import datetime\n",
    "# Here we go\n",
    "#start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "random_search.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_child_weight': 1,\n",
       " 'max_depth': 5,\n",
       " 'learning_rate': 0.2,\n",
       " 'colsample_bytree': 0.7}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
